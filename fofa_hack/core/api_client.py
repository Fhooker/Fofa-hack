"""
åŸºäºRSAç­¾åçš„Fofa APIå®¢æˆ·ç«¯
æ”¯æŒåŒ¿åè®¿é—®ï¼Œæ— éœ€APIå¯†é’¥
"""
import base64
import json
import time
import urllib.parse
from typing import List, Optional, Dict, Any

import httpx
from Cryptodome.Signature import PKCS1_v1_5
from Cryptodome.Hash import SHA256
from Cryptodome.PublicKey import RSA

from ..models.search import SearchConfig, SearchResult, FofaResponse
from ..utils.logger import get_logger

logger = get_logger(__name__)


# RSAç§é’¥ï¼ˆç”¨äºç”Ÿæˆç­¾åï¼‰
RSA_PRIVATE_KEY = '''-----BEGIN RSA PRIVATE KEY-----
MIIEogIBAAKCAQEAv0xjefuBTF6Ox940ZqLLUFFBDtTcB9dAfDjWgyZ2A55K+VdG
c1L5LqJWuyRkhYGFTlI4K5hRiExvjXuwIEed1norp5cKdeTLJwmvPyFgaEh7Ow19
Tu9sTR5hHxThjT8ieArB2kNAdp8Xoo7O8KihmBmtbJ1umRv2XxG+mm2ByPZFlTdW
RFU38oCPkGKlrl/RzOJKRYMv10s1MWBPY6oYkRiOX/EsAUVae6zKRqNR2Q4HzJV8
gOYMPvqkau8hwN8i6r0z0jkDGCRJSW9djWk3Byi3R2oSdZ0IoS+91MFtKvWYdnNH
2Ubhlnu1P+wbeuIFdp2u7ZQOtgPX0mtQ263e5QIDAQABAoIBAD67GwfeTMkxXNr3
5/EcQ1XEP3RQoxLDKHdT4CxDyYFoQCfB0e1xcRs0ywI1be1FyuQjHB5Xpazve8lG
nTwIoB68E2KyqhB9BY14pIosNMQduKNlygi/hKFJbAnYPBqocHIy/NzJHvOHOiXp
dL0AX3VUPkWW3rTAsar9U6aqcFvorMJQ2NPjijcXA0p1MlZAZKODO2wqidfQ487h
xy0ZkriYVi419j83a1cCK0QocXiUUeQM6zRNgQv7LCmrFo2X4JEzlujEveqvsDC4
MBRgkK2lNH+AFuRwOEr4PIlk9rrpHA4O1V13P3hJpH5gxs5oLLM1CWWG9YWLL44G
zD9Tm8ECgYEA8NStMXyAmHLYmd2h0u5jpNGbegf96z9s/RnCVbNHmIqh/pbXizcv
mMeLR7a0BLs9eiCpjNf9hob/JCJTms6SmqJ5NyRMJtZghF6YJuCSO1MTxkI/6RUw
mrygQTiF8RyVUlEoNJyhZCVWqCYjctAisEDaBRnUTpNn0mLvEXgf1pUCgYEAy1kE
d0YqGh/z4c/D09crQMrR/lvTOD+LRMf9lH+SkScT0GzdNIT5yuscRwKsnE6SpC5G
ySJFVhCnCBsQqq+ohsrXt8a99G7ePTMSAGK3QtC7QS3liDmvPBk6mJiLrKiRAZos
vgPg7nTP8VuF0ZIKzkdWbGoMyNxVFZXovQ8BYxECgYBvCR9xGX4Qy6KiDlV18wNu
ElYkxVqFBBE0AJRg/u+bnQ9jWhi2zxLa1eWZgtss80c876I8lbkGNWedOVZioatm
MFLC4bFalqyZWyO7iP7i60LKvfDJfkOSlDUu3OikahFOiqyG1VBz4+M4U500alIU
AVKD14zTTZMopQSkgUXsoQKBgHd8RgiD3Qde0SJVv97BZzP6OWw5rqI1jHMNBK72
SzwpdxYYcd6DaHfYsNP0+VIbRUVdv9A95/oLbOpxZNi2wNL7a8gb6tAvOT1Cvggl
+UM0fWNuQZpLMvGgbXLu59u7bQFBA5tfkhLr5qgOvFIJe3n8JwcrRXndJc26OXil
0Y3RAoGAJOqYN2CD4vOs6CHdnQvyn7ICc41ila/H49fjsiJ70RUD1aD8nYuosOnj
wbG6+eWekyLZ1RVEw3eRF+aMOEFNaK6xKjXGMhuWj3A9xVw9Fauv8a2KBU42Vmcd
t4HRyaBPCQQsIoErdChZj8g7DdxWheuiKoN4gbfK4W1APCcuhUA=
-----END RSA PRIVATE KEY-----'''


class RsaSigner:
    """RSAç­¾åç”Ÿæˆå™¨"""

    def __init__(self, private_key: str = RSA_PRIVATE_KEY):
        self.private_key = private_key

    def sign(self, message: str) -> str:
        """ç”Ÿæˆç­¾å"""
        priv_key = RSA.importKey(self.private_key)
        h = SHA256.new(message.encode('utf-8'))
        signature = PKCS1_v1_5.new(priv_key).sign(h)
        return base64.b64encode(signature).decode()

    def build_signed_url(self, query: str, page: int = 1, size: int = 20, full: bool = False) -> str:
        """
        æ„å»ºå¸¦ç­¾åçš„API URL

        Args:
            query: æœç´¢æŸ¥è¯¢
            page: é¡µç 
            size: æ¯é¡µæ•°é‡
            full: æ˜¯å¦æœç´¢å…¨éƒ¨æ•°æ®ï¼ˆé»˜è®¤åªæœç´¢æœ€è¿‘ä¸€å¹´ï¼‰

        Returns:
            ç­¾åçš„API URL
        """
        qbase64 = base64.b64encode(query.encode('utf-8')).decode()
        ts = int(time.time() * 1000)

        # æ„å»ºç­¾åæ¶ˆæ¯ï¼ˆæ³¨æ„ï¼šå‚æ•°é¡ºåºå¾ˆé‡è¦ï¼‰
        message = f'full{str(full).lower()}page{page}qbase64{qbase64}size{size}ts{ts}'
        sign = urllib.parse.quote(self.sign(message))

        # æ„å»ºURL
        url = (
            f'https://api.fofa.info/v1/search?'
            f'qbase64={urllib.parse.quote(qbase64)}&'
            f'full={str(full).lower()}&'
            f'page={page}&'
            f'size={size}&'
            f'ts={ts}&'
            f'sign={sign}&'
            f'app_id=9e9fb94330d97833acfbc041ee1a76793f1bc691'
        )
        return url


class ApiFofaClient:
    """åŸºäºAPIçš„Fofaå®¢æˆ·ç«¯"""

    def __init__(self, config: SearchConfig):
        self.config = config
        self.signer = RsaSigner()

        # é…ç½®HTTPå®¢æˆ·ç«¯
        timeout = httpx.Timeout(config.timeout, connect=30.0)
        limits = httpx.Limits(max_connections=10, max_keepalive_connections=5)

        self.client = httpx.Client(
            timeout=timeout,
            limits=limits,
            follow_redirects=True,
            http2=True
        )

        # è®¾ç½®ä»£ç†
        if config.proxy:
            self.client.proxies = {"all://": config.proxy}

        # è®¾ç½®è¯·æ±‚å¤´
        self.client.headers.update({
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "application/json, text/plain, */*",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
            "Referer": "https://fofa.info/",
            "Origin": "https://fofa.info",
            "X-Requested-With": "XMLHttpRequest"
        })

        # é€Ÿç‡é™åˆ¶
        self.request_count = 0
        self.last_request_time = 0

    def _rate_limit(self):
        """é€Ÿç‡é™åˆ¶æ§åˆ¶"""
        current_time = time.time()
        elapsed = current_time - self.last_request_time

        min_interval = self.config.time_sleep
        if elapsed < min_interval:
            sleep_time = min_interval - elapsed
            time.sleep(sleep_time)

        self.last_request_time = time.time()
        self.request_count += 1

    def _make_request(self, url: str, max_retries: int = 3) -> Optional[Dict[str, Any]]:
        """
        æ‰§è¡ŒAPIè¯·æ±‚ï¼Œå¸¦é‡è¯•æœºåˆ¶

        Args:
            url: è¯·æ±‚URL
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°

        Returns:
            JSONå“åº”æ•°æ®
        """
        for attempt in range(max_retries):
            try:
                self._rate_limit()

                if self.config.debug:
                    logger.debug(f"è¯·æ±‚URL: {url}")
                    logger.debug(f"å°è¯•æ¬¡æ•°: {attempt + 1}/{max_retries}")

                response = self.client.get(url)
                response.raise_for_status()

                data = response.json()

                # æ£€æŸ¥æ˜¯å¦è¢«å°ç¦
                if data.get('code') == -3000:
                    error_msg = data.get('message', 'IPè¢«å°ç¦')
                    logger.error(f"APIé”™è¯¯: {error_msg}")

                    if self.config.proxy:
                        logger.info("å°è¯•åˆ‡æ¢ä»£ç†æˆ–å¢åŠ å»¶è¿Ÿ...")
                    else:
                        logger.warning("å»ºè®®ä½¿ç”¨ä»£ç†æ¥é¿å…IPå°ç¦")

                    return None

                # æ£€æŸ¥æ˜¯å¦éœ€è¦éªŒè¯ç ï¼ˆ2025å¹´Fofaæ–°æœºåˆ¶ï¼‰
                if data.get('code') == 850100:
                    error_msg = data.get('message', 'éœ€è¦å®ŒæˆéªŒè¯ç ')
                    logger.error(f"APIé”™è¯¯: {error_msg}")
                    logger.error("ğŸš¨ Fofaå·²å¯ç”¨éªŒè¯ç éªŒè¯ï¼Œå…¬å…±ä»£ç†æ— æ³•ä½¿ç”¨ï¼")
                    logger.error("ğŸ’¡ å»ºè®®æ–¹æ¡ˆï¼š")
                    logger.error("   1. ä½¿ç”¨--no-proxyå‚æ•°å°è¯•ç›´è¿ï¼ˆå¯èƒ½ä»éœ€éªŒè¯ç ï¼‰")
                    logger.error("   2. æ‰‹åŠ¨ç™»å½•Fofaè´¦å·è·å–cookie")
                    logger.error("   3. æ›´æ¢é«˜è´¨é‡ç§å¯†ä»£ç†")
                    return None

                # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
                if data.get('code') == 0 or 'data' in data:
                    return data

                # å…¶ä»–é”™è¯¯
                logger.warning(f"æœªçŸ¥å“åº”: {data}")
                return None

            except httpx.HTTPStatusError as e:
                logger.error(f"HTTPé”™è¯¯ ({attempt + 1}/{max_retries}): {e.response.status_code}")
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 2  # æŒ‡æ•°é€€é¿
                    logger.info(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)

            except json.JSONDecodeError as e:
                logger.error(f"JSONè§£æé”™è¯¯ ({attempt + 1}/{max_retries}): {e}")
                if self.config.debug:
                    logger.debug(f"åŸå§‹å“åº”: {response.text[:500]}")

            except Exception as e:
                logger.error(f"è¯·æ±‚å¼‚å¸¸ ({attempt + 1}/{max_retries}): {e}")

            # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
            if attempt == max_retries - 1:
                logger.error(f"è¯·æ±‚å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡")
                return None

        return None

    def search(self, query: str, page: int = 1, size: Optional[int] = None) -> Optional[FofaResponse]:
        """
        æ‰§è¡Œæœç´¢

        Args:
            query: æœç´¢æŸ¥è¯¢
            page: é¡µç 
            size: æ¯é¡µæ•°é‡ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„end_countï¼Œä½†ä¸è¶…è¿‡10000ï¼‰

        Returns:
            FofaResponseå¯¹è±¡
        """
        if size is None:
            # APIé™åˆ¶å•æ¬¡æœ€å¤š10000æ¡
            size = min(self.config.end_count, 10000)

        url = self.signer.build_signed_url(query, page=page, size=size)

        data = self._make_request(url)
        if not data:
            return None

        # è§£ææ•°æ®
        api_data = data.get('data', {})
        if not api_data:
            logger.warning("APIè¿”å›æ•°æ®ä¸ºç©º")
            return FofaResponse(code=data.get('code', -1), message=data.get('message', 'æœªçŸ¥é”™è¯¯'), data={})

        assets = api_data.get('assets', [])
        total = api_data.get('total', 0)

        # è½¬æ¢ä¸ºSearchResultåˆ—è¡¨
        results = []
        for asset in assets:
            result = SearchResult(
                link=asset.get('link', ''),
                host=asset.get('host', ''),
                port=int(asset.get('port', 0)) if asset.get('port') else 0,
                title=asset.get('title', ''),
                ip=asset.get('ip', ''),
                city=asset.get('city', ''),
                asn=str(asset.get('asn', '')),
                organization=asset.get('organization', ''),
                server=asset.get('server', ''),
                mtime=asset.get('mtime', '')
            )
            results.append(result)

        return FofaResponse(
            code=200,
            message='success',
            data={
                'assets': [r.model_dump() for r in results],
                'total': total,
                'page': page
            }
        )

    def search_all(self, query: str, max_pages: int = 10) -> List[SearchResult]:
        """
        æœç´¢æ‰€æœ‰é¡µé¢ç›´åˆ°è¾¾åˆ°ç›®æ ‡æ•°é‡

        Args:
            query: æœç´¢æŸ¥è¯¢
            max_pages: æœ€å¤§é¡µæ•°

        Returns:
            æ‰€æœ‰æœç´¢ç»“æœ
        """
        all_results = []
        page = 1

        while len(all_results) < self.config.end_count and page <= max_pages:
            response = self.search(query, page=page)

            if not response:
                logger.warning(f"ç¬¬{page}é¡µæœç´¢å¤±è´¥ï¼Œåœæ­¢æœç´¢")
                break

            results = response.get_assets()
            if not results:
                logger.info(f"ç¬¬{page}é¡µæ— ç»“æœï¼Œæœç´¢å®Œæˆ")
                break

            all_results.extend(results)
            logger.info(f"å·²è·å–ç¬¬{page}é¡µï¼Œå…±{len(results)}æ¡ï¼Œæ€»è®¡{len(all_results)}æ¡")

            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡æ•°é‡
            if len(all_results) >= self.config.end_count:
                all_results = all_results[:self.config.end_count]
                break

            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šç»“æœ
            total = response.get_total()
            if total > 0 and len(all_results) >= total:
                logger.info(f"å·²è·å–æ‰€æœ‰ç»“æœï¼ˆå…±{total}æ¡ï¼‰")
                break

            page += 1

        return all_results

    def get_count(self, query: str) -> int:
        """
        è·å–æœç´¢ç»“æœæ€»æ•°

        Args:
            query: æœç´¢æŸ¥è¯¢

        Returns:
            ç»“æœæ€»æ•°
        """
        response = self.search(query, page=1, size=1)
        if response:
            return response.get_total()
        return -1  # -1è¡¨ç¤ºæŸ¥è¯¢å¤±è´¥


class MultiQueryApiClient:
    """å¤šæŸ¥è¯¢APIå®¢æˆ·ç«¯"""

    def __init__(self, config: SearchConfig):
        self.config = config
        self.client = ApiFofaClient(config)

    def search_batch(self, queries: List[str]) -> Dict[str, List[SearchResult]]:
        """
        æ‰¹é‡æœç´¢å¤šä¸ªæŸ¥è¯¢

        Args:
            queries: æŸ¥è¯¢åˆ—è¡¨

        Returns:
            {query: results} çš„å­—å…¸
        """
        results = {}

        for i, query in enumerate(queries, 1):
            logger.info(f"[{i}/{len(queries)}] å¼€å§‹æœç´¢: {query}")
            query_results = self.client.search_all(query)
            results[query] = query_results
            logger.info(f"[{i}/{len(queries)}] æœç´¢å®Œæˆ: {query}, ç»“æœæ•°: {len(query_results)}")

            # æ‰¹é‡æœç´¢æ—¶çš„é¢å¤–å»¶è¿Ÿ
            if self.config.time_sleep > 0:
                time.sleep(self.config.time_sleep)

        return results

    async def search_batch_async(self, queries: List[str]) -> Dict[str, List[SearchResult]]:
        """
        å¼‚æ­¥æ‰¹é‡æœç´¢ï¼ˆéœ€è¦å®ç°å¼‚æ­¥å®¢æˆ·ç«¯ï¼‰

        Args:
            queries: æŸ¥è¯¢åˆ—è¡¨

        Returns:
            {query: results} çš„å­—å…¸
        """
        # åŒæ­¥å®ç°ï¼ˆå¼‚æ­¥éœ€è¦é¢å¤–çš„å¼‚æ­¥HTTPå®¢æˆ·ç«¯ï¼‰
        return self.search_batch(queries)


def create_client(config: SearchConfig):
    """
    åˆ›å»ºåˆé€‚çš„å®¢æˆ·ç«¯

    Args:
        config: é…ç½®å¯¹è±¡

    Returns:
        å®¢æˆ·ç«¯å®ä¾‹
    """
    # ä¼˜å…ˆä½¿ç”¨APIå®¢æˆ·ç«¯ï¼ˆåŸºäºRSAç­¾åï¼‰
    return ApiFofaClient(config)